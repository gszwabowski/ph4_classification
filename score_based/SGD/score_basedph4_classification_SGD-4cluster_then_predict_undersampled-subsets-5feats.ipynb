{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing, neighbors\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "from typing import Tuple\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import csv\n",
    "\n",
    "randomstate = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster test/train data\n",
    "def get_clusters(X_train: pd.DataFrame, X_test: pd.DataFrame, n_clusters: int) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    applies k-means clustering to training data to find clusters and predicts them for the test set\n",
    "    \"\"\"\n",
    "    clustering = KMeans(n_clusters=n_clusters, random_state=randomstate)\n",
    "    clustering.fit(X_train)\n",
    "    # apply the labels\n",
    "    train_labels = clustering.labels_\n",
    "    X_train_clstrs = X_train.copy()\n",
    "    X_train_clstrs['clusters'] = train_labels\n",
    "    \n",
    "    # predict labels on the test set\n",
    "    test_labels = clustering.predict(X_test)\n",
    "    X_test_clstrs = X_test.copy()\n",
    "    X_test_clstrs['clusters'] = test_labels\n",
    "    return X_train_clstrs, X_test_clstrs\n",
    "\n",
    "#scale each feature\n",
    "def scale_features(X_train: pd.DataFrame, X_test: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    applies standard scaler (z-scores) to training data and predicts z-scores for the test set\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    to_scale = [col for col in X_train.columns.values]\n",
    "    scaler.fit(X_train[to_scale])\n",
    "    X_train[to_scale] = scaler.transform(X_train[to_scale])\n",
    "    \n",
    "    # predict z-scores on the test set\n",
    "    X_test[to_scale] = scaler.transform(X_test[to_scale])\n",
    "    \n",
    "    return X_train, X_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors: ['Hits', 'max_feat', 'avg_feat', 'max_centr', 'min_centr', 'avg_centr', 'features', 'all_same', 's_score', 'hyd_prop', 'don_prop', 'catdon_prop', 'hydaro_prop', 'aniacc_prop'] \n",
      "\n",
      "x_train Q ph4s: 2699 \n",
      "\n",
      "x_test Q ph4s: 922 \n",
      "\n",
      "[-2.261291652098838, -0.6232776848498619, 1.0147362823991142, 2.65275024964809]\n",
      "X_train 1/2/3/4 cluster values\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "[-2.26129165]\n",
      "[-0.62327768]\n",
      "[1.01473628]\n",
      "[2.65275025] \n",
      "\n",
      "0 cluster model\n",
      "\n",
      "Predicted   0   1\n",
      "Actual           \n",
      "0          31  17\n",
      "1          40  70 \n",
      "\n",
      "PPV: 0.80 \n",
      "\n",
      "1 cluster model\n",
      "\n",
      "Predicted    0    1\n",
      "Actual             \n",
      "0          470  319\n",
      "1           27  594 \n",
      "\n",
      "PPV: 0.65\n",
      "2 cluster model\n",
      "\n",
      "Predicted    0    1\n",
      "Actual             \n",
      "0          860   85\n",
      "1            2  172 \n",
      "\n",
      "PPV: 0.67 \n",
      "\n",
      "3 cluster model\n",
      "\n",
      "Predicted  0   1\n",
      "Actual          \n",
      "0          9   3\n",
      "1          5  12 \n",
      "\n",
      "PPV: 0.80\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('..\\..\\data\\_All_Receptors_runs_1_2_3_binary.csv')\n",
    "df.drop(['min_feat','receptor','Active_Rate','Enrichment', 'GH', 'Actives', 'filename', 'fbase', 'hyd', 'don', 'acc', 'ani', 'cat', 'aro', 'donhyd', 'catdon', 'hydaro', 'aniacc', 'donacc', 'acc_prop', 'ani_prop', 'cat_prop', 'aro_prop', 'donhyd_prop', 'donacc_prop'], 1, inplace=True)\n",
    "df.fillna(-99999)\n",
    "    \n",
    "predictors = list(df.columns)\n",
    "predictors = predictors[:-1]\n",
    "    \n",
    "print('Predictors:', predictors,'\\n')\n",
    "    \n",
    "np.random.seed(randomstate)\n",
    "\n",
    "#split data into quality/not quality sets\n",
    "q_ph4s = df[df['quality'] == 1]\n",
    "nq_ph4s = df[df['quality'] != 1]\n",
    "    \n",
    "#ensure that there is an equal number of nq ph4s\n",
    "nq_ph4s = nq_ph4s.sample(n=2*len(q_ph4s))\n",
    "\n",
    "#merge arrays prior to TTS\n",
    "frames = [q_ph4s, nq_ph4s]\n",
    "df = pd.concat(frames)\n",
    "\n",
    "#x is features, y is classes\n",
    "x = df.drop('quality', 1)\n",
    "y = df.quality\n",
    "    \n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=randomstate)\n",
    "    \n",
    "    \n",
    "print(\"x_train Q ph4s:\", y_train.sum(),'\\n')\n",
    "print(\"x_test Q ph4s:\",y_test.sum(),'\\n')\n",
    "    \n",
    "X_train_clstrs, X_test_clstrs = get_clusters(x_train, x_test, 4)\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "#print(X_train_clstrs['clusters'].unique())\n",
    "clusters = X_train_clstrs['clusters']\n",
    "\n",
    "X_train_scaled, X_test_scaled = scale_features(X_train_clstrs, X_test_clstrs)\n",
    "    \n",
    "#print(X_train_scaled)\n",
    "    \n",
    "# to divide the df by cluster, we need to ensure we use the correct class labels, we'll use pandas to do that\n",
    "train_clusters = X_train_scaled.copy()\n",
    "test_clusters = X_test_scaled.copy()\n",
    "train_clusters['y'] = y_train\n",
    "test_clusters['y'] = y_test\n",
    "\n",
    "uniq_clusters = train_clusters['clusters'].unique()\n",
    "uniqs = uniq_clusters.tolist()\n",
    "uniqs.sort()\n",
    "print(uniqs)\n",
    "\n",
    "#print(y_train)\n",
    "#print(train_clusters['clusters'])\n",
    "\n",
    "#print(type(clusters))\n",
    "#print(type(train_clusters['clusters']))\n",
    "#frames = [clusters, train_clusters['clusters']]\n",
    "#df = pd.concat(frames, axis=1)\n",
    "#print(type(df))\n",
    "#print(df)\n",
    "#df.to_csv('4clusters.csv')\n",
    "\n",
    "# locate the \"0\" cluster\n",
    "train_0 = train_clusters.loc[train_clusters.clusters <= uniqs[0]] # after scaling, 0 went to -2.187\n",
    "test_0 = test_clusters.loc[test_clusters.clusters <= uniqs[0]]\n",
    "y_train_0 = train_0.y.values\n",
    "y_test_0 = test_0.y.values\n",
    "# locate the \"1\" cluster\n",
    "train_1 = train_clusters.loc[(train_clusters.clusters <= uniqs[1]) & (train_clusters.clusters > uniqs[0])] # after scaling, 1 went to -0.62\n",
    "test_1 = test_clusters.loc[(test_clusters.clusters <= uniqs[1]) & (test_clusters.clusters > uniqs[0])]\n",
    "y_train_1 = train_1.y.values\n",
    "y_test_1 = test_1.y.values\n",
    "\n",
    "# locate the \"2\" cluster\n",
    "train_2 = train_clusters.loc[(train_clusters.clusters <= uniqs[2]) & (train_clusters.clusters > uniqs[1])] # after scaling, 2 went to 0.945\n",
    "test_2 = test_clusters.loc[(test_clusters.clusters <= uniqs[2]) & (test_clusters.clusters > uniqs[1])]\n",
    "y_train_2 = train_2.y.values\n",
    "y_test_2 = test_2.y.values\n",
    "\n",
    "# locate the \"3\" cluster\n",
    "train_3 = train_clusters.loc[train_clusters.clusters >= uniqs[3]] # after scaling, 3 went to 2.51\n",
    "test_3 = test_clusters.loc[test_clusters.clusters >= uniqs[3]]\n",
    "y_train_3 = train_3.y.values\n",
    "y_test_3 = test_3.y.values\n",
    "\n",
    "# drop the targets from the training set\n",
    "X_train_0 = train_0.drop(columns=['y'])\n",
    "X_test_0 = test_0.drop(columns=['y'])\n",
    "X_train_1 = train_1.drop(columns=['y'])\n",
    "X_test_1 = test_1.drop(columns=['y'])\n",
    "X_train_2 = train_2.drop(columns=['y'])\n",
    "X_test_2 = test_2.drop(columns=['y'])\n",
    "X_train_3 = train_3.drop(columns=['y'])\n",
    "X_test_3 = test_3.drop(columns=['y'])\n",
    "\n",
    "print('X_train 1/2/3/4 cluster values\\n')\n",
    "print('-------------------------------\\n')\n",
    "print(X_train_0['clusters'].unique())\n",
    "print(X_train_1['clusters'].unique())\n",
    "print(X_train_2['clusters'].unique())\n",
    "print(X_train_3['clusters'].unique(),'\\n')\n",
    "\n",
    "#print(X_train_0)\n",
    "#print(len(X_test_1))\n",
    "\n",
    "    \n",
    "#0 cluster LR model\n",
    "sgdc0 = SGDClassifier(loss=\"log\", penalty=\"l1\", max_iter=1000, tol=1e-2, class_weight='balanced')\n",
    "sgdc0.fit(X_train_0, y_train_0)\n",
    "    \n",
    "y_pred = (sgdc0.predict(X_test_0))\n",
    "confmat = confusion_matrix(y_test_0, y_pred, labels=[0,1])\n",
    "#print(confmat)\n",
    "    \n",
    "confmat = confusion_matrix(y_test_0, y_pred, labels=[0,1]).ravel()\n",
    "FP = (confmat[1])\n",
    "TP = (confmat[3])\n",
    "    \n",
    "PPV = (TP / (TP + FP))\n",
    "    \n",
    "cm = pd.crosstab(y_test_0, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=False)\n",
    "    \n",
    "print('0 cluster model\\n')\n",
    "print(cm,'\\n')\n",
    "    \n",
    "print('PPV:', format(PPV, '.2f'),'\\n')\n",
    "    \n",
    "#1 cluster LR model\n",
    "sgdc1 = SGDClassifier(loss=\"log\", penalty=\"l1\", max_iter=1000, tol=1e-2, class_weight='balanced')\n",
    "sgdc1.fit(X_train_1, y_train_1)\n",
    "    \n",
    "y_pred = (sgdc1.predict(X_test_1))\n",
    "confmat = confusion_matrix(y_test_1, y_pred, labels=[0,1])\n",
    "    \n",
    "confmat = confusion_matrix(y_test_1, y_pred, labels=[0,1]).ravel()\n",
    "FP = (confmat[1])\n",
    "TP = (confmat[3])\n",
    "    \n",
    "PPV = (TP / (TP + FP))\n",
    "    \n",
    "cm = pd.crosstab(y_test_1, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=False)\n",
    "    \n",
    "print('1 cluster model\\n')\n",
    "print(cm,'\\n')\n",
    "\n",
    "print('PPV:', format(PPV, '.2f'))\n",
    "\n",
    "#print(X_train_0)\n",
    "#print(len(X_train_2))\n",
    "\n",
    "#2 cluster LR model\n",
    "sgdc2 = SGDClassifier(loss=\"log\", penalty=\"l1\", max_iter=1000, tol=1e-2, class_weight='balanced')\n",
    "sgdc2.fit(X_train_2, y_train_2)\n",
    "    \n",
    "y_pred = (sgdc2.predict(X_test_2))\n",
    "confmat = confusion_matrix(y_test_2, y_pred, labels=[0,1])\n",
    "#print(confmat)\n",
    "    \n",
    "confmat = confusion_matrix(y_test_2, y_pred, labels=[0,1]).ravel()\n",
    "FP = (confmat[1])\n",
    "TP = (confmat[3])\n",
    "    \n",
    "PPV = (TP / (TP + FP))\n",
    "    \n",
    "cm = pd.crosstab(y_test_2, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=False)\n",
    "    \n",
    "print('2 cluster model\\n')\n",
    "print(cm,'\\n')\n",
    "    \n",
    "print('PPV:', format(PPV, '.2f'),'\\n')\n",
    "    \n",
    "#3 cluster LR model\n",
    "sgdc3 = SGDClassifier(loss=\"log\", penalty=\"l1\", max_iter=1000, tol=1e-2, class_weight='balanced')\n",
    "sgdc3.fit(X_train_3, y_train_3)\n",
    "    \n",
    "y_pred = (sgdc3.predict(X_test_3))\n",
    "confmat = confusion_matrix(y_test_3, y_pred, labels=[0,1])\n",
    "#print(confmat)\n",
    "    \n",
    "confmat = confusion_matrix(y_test_3, y_pred, labels=[0,1]).ravel()\n",
    "FP = (confmat[1])\n",
    "TP = (confmat[3])\n",
    "    \n",
    "PPV = (TP / (TP + FP))\n",
    "    \n",
    "cm = pd.crosstab(y_test_3, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=False)\n",
    "    \n",
    "print('3 cluster model\\n')\n",
    "print(cm,'\\n')\n",
    "\n",
    "print('PPV:', format(PPV, '.2f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def scale_features_single(X: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    applies standard scaler (z-scores) to training data and predicts z-scores for the test set\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    to_scale = [col for col in X.columns.values]\n",
    "    scaler.fit(X[to_scale])\n",
    "    X[to_scale] = scaler.transform(X[to_scale])\n",
    "    \n",
    "    return X\n",
    "\n",
    "def classify_ext_data(subset):\n",
    "    #CLassify external data (score based pharmacophore models)\n",
    "    if subset == \"moe\":\n",
    "        ext_df = pd.read_csv('..\\\\..\\\\data\\\\5feat\\\\score_based_moefrags_data_binary_5feats.csv')\n",
    "    elif subset == \"EF\":\n",
    "        ext_df = pd.read_csv('..\\\\..\\\\data\\\\5feat\\\\score_based_efdata_binary_5feats.csv')\n",
    "    elif subset == \"GH\":\n",
    "        ext_df = pd.read_csv('..\\\\..\\\\data\\\\5feat\\\\score_based_ghdata_binary_5feats.csv')\n",
    "    elif subset == \"rec_ef\":\n",
    "        ext_df = pd.read_csv('..\\\\..\\\\data\\\\5feat\\\\score_based_recefdata_binary_5feats.csv')\n",
    "    elif subset == \"rec_gh\":\n",
    "        ext_df = pd.read_csv('..\\\\..\\\\data\\\\5feat\\\\score_based_recghdata_binary_5feats.csv')\n",
    "    elif subset == \"moe_ef_gh\":\n",
    "        ext_df = pd.read_csv('..\\\\..\\\\data\\\\5feat\\\\score_based_moeefgh_data_binary_5feats.csv')\n",
    "    elif subset == \"all\":\n",
    "        ext_df = pd.read_csv('..\\\\..\\\\data\\\\5feat\\\\score_based_alldata_binary_5feats.csv')\n",
    "        \n",
    "    ext_df.drop(['min_feat','Receptor', 'Score Type','Enrichment',  'hyd', 'don', 'acc', 'donhyd', 'catdon', 'hydaro', 'aniacc', 'donacc', 'acc_prop', 'donhyd_prop', 'donacc_prop'], 1, inplace=True)\n",
    "    \n",
    "    #drop extra column from data with searches\n",
    "    if subset == \"moe_searches\":\n",
    "        ext_df.drop(['search_features'], 1, inplace=True)\n",
    "        \n",
    "    ext_df.fillna(-99999)\n",
    "    x = ext_df.drop('quality', 1)\n",
    "    y = ext_df.quality\n",
    "    \n",
    "    predictors = list(ext_df.columns)\n",
    "    predictors = predictors[:-1]\n",
    "    print('Predictors:', predictors,'\\n')\n",
    "    \n",
    "    print(\"score based Q ph4s:\", y.sum(),'\\n')\n",
    "    \n",
    "    clustering = KMeans(n_clusters=4, random_state=randomstate)\n",
    "    clustering.fit(x)\n",
    "    \n",
    "    train_labels = clustering.labels_\n",
    "    \n",
    "    X_clstrs = x.copy()\n",
    "    X_clstrs['clusters'] = train_labels\n",
    "    \n",
    "    X_scaled = scale_features_single(X_clstrs)\n",
    "    ext_clusters = X_scaled.copy()\n",
    "    ext_clusters['y'] = y\n",
    "    \n",
    "    # locate the \"0\" cluster\n",
    "    ext_0 = ext_clusters.loc[ext_clusters.clusters <= uniqs[0]] # after scaling, 0 went negtive\n",
    "    y_ext_0 = ext_0.y.values\n",
    "    \n",
    "    # locate the \"1\" cluster\n",
    "    ext_1 = ext_clusters.loc[(ext_clusters.clusters <= uniqs[1]) & (ext_clusters.clusters > uniqs[0])] # after scaling, 0 went negtive\n",
    "    y_ext_1 = ext_1.y.values\n",
    "    \n",
    "    # locate the \"2\" cluster\n",
    "    ext_2 = ext_clusters.loc[(ext_clusters.clusters <= uniqs[2]) & (ext_clusters.clusters > uniqs[1])] # after scaling, 0 went negtive\n",
    "    y_ext_2 = ext_2.y.values\n",
    "    \n",
    "    # locate the \"3\" cluster\n",
    "    ext_3 = ext_clusters.loc[ext_clusters.clusters > uniqs[3] ] # after scaling, 0 went negtive\n",
    "    y_ext_3 = ext_3.y.values\n",
    "\n",
    "    # drop the targets from the external set\n",
    "    X_ext_0 = ext_0.drop(columns=['y'])\n",
    "    X_ext_1 = ext_1.drop(columns=['y'])\n",
    "    X_ext_2 = ext_2.drop(columns=['y'])\n",
    "    X_ext_3 = ext_3.drop(columns=['y'])\n",
    "    \n",
    "    #print(len(X_ext_0))\n",
    "    #print(len(X_ext_1))\n",
    "    #print(len(X_ext_2))\n",
    "    #print(len(X_ext_3))\n",
    "    \n",
    "    #predict based on 0 cluster model\n",
    "    print('0 cluster model\\n')\n",
    "    if len(X_ext_0) == 0:\n",
    "        print('No cluster 0 data.\\n')\n",
    "    else:\n",
    "        y_pred = (sgdc0.predict(X_ext_0))\n",
    "        confmat = confusion_matrix(y_ext_0, y_pred, labels=[0,1])\n",
    "        #print(confmat)\n",
    "\n",
    "        confmat = confusion_matrix(y_ext_0, y_pred, labels=[0,1]).ravel()\n",
    "        FP = (confmat[1])\n",
    "        TP = (confmat[3])\n",
    "\n",
    "        PPV = (TP / (TP + FP))\n",
    "\n",
    "        cm = pd.crosstab(y_ext_0, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=False)\n",
    "\n",
    "    \n",
    "        print(cm,'\\n')\n",
    "\n",
    "        print('PPV:', format(PPV, '.2f'),'\\n')\n",
    "\n",
    "    print('1 cluster model\\n')\n",
    "    if len(X_ext_1) == 0:\n",
    "        print('No cluster 1 data.\\n')\n",
    "    else:\n",
    "        y_pred = (sgdc1.predict(X_ext_1))\n",
    "        confmat = confusion_matrix(y_ext_1, y_pred, labels=[0,1])\n",
    "        #print(confmat)\n",
    "\n",
    "        confmat = confusion_matrix(y_ext_1, y_pred, labels=[0,1]).ravel()\n",
    "        FP = (confmat[1])\n",
    "        TP = (confmat[3])\n",
    "\n",
    "        PPV = (TP / (TP + FP))\n",
    "\n",
    "        cm = pd.crosstab(y_ext_1, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=False)\n",
    "\n",
    "    \n",
    "        print(cm,'\\n')\n",
    "\n",
    "        print('PPV:', format(PPV, '.2f'),'\\n')\n",
    "        \n",
    "    print('2 cluster model\\n')\n",
    "    if len(X_ext_2) == 0:\n",
    "        print('No cluster 2 data.\\n')\n",
    "    else:\n",
    "        y_pred = (sgdc2.predict(X_ext_2))\n",
    "        confmat = confusion_matrix(y_ext_2, y_pred, labels=[0,1])\n",
    "        #print(confmat)\n",
    "\n",
    "        confmat = confusion_matrix(y_ext_2, y_pred, labels=[0,1]).ravel()\n",
    "        FP = (confmat[1])\n",
    "        TP = (confmat[3])\n",
    "\n",
    "        PPV = (TP / (TP + FP))\n",
    "\n",
    "        cm = pd.crosstab(y_ext_2, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=False)\n",
    "\n",
    "    \n",
    "        print(cm,'\\n')\n",
    "\n",
    "        print('PPV:', format(PPV, '.2f'),'\\n')\n",
    "        \n",
    "    print('3 cluster model\\n')\n",
    "    if len(X_ext_3) == 0:\n",
    "        print('No cluster 3 data.\\n')\n",
    "    else:\n",
    "        y_pred = (sgdc3.predict(X_ext_3))\n",
    "        confmat = confusion_matrix(y_ext_3, y_pred, labels=[0,1])\n",
    "        #print(confmat)\n",
    "\n",
    "        confmat = confusion_matrix(y_ext_3, y_pred, labels=[0,1]).ravel()\n",
    "        FP = (confmat[1])\n",
    "        TP = (confmat[3])\n",
    "\n",
    "        PPV = (TP / (TP + FP))\n",
    "\n",
    "        cm = pd.crosstab(y_ext_3, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=False)\n",
    "\n",
    "    \n",
    "        print(cm,'\\n')\n",
    "\n",
    "        print('PPV:', format(PPV, '.2f'),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors: ['s_score', 'Hits', 'max_feat', 'avg_feat', 'max_centr', 'min_centr', 'avg_centr', 'features', 'all_same', 'hyd_prop', 'don_prop', 'catdon_prop', 'hydaro_prop', 'aniacc_prop'] \n",
      "\n",
      "score based Q ph4s: 19 \n",
      "\n",
      "0 cluster model\n",
      "\n",
      "No cluster 0 data.\n",
      "\n",
      "1 cluster model\n",
      "\n",
      "Predicted   0   1\n",
      "Actual           \n",
      "0          30  28\n",
      "1           7  12 \n",
      "\n",
      "PPV: 0.30 \n",
      "\n",
      "2 cluster model\n",
      "\n",
      "Predicted   0  1\n",
      "Actual          \n",
      "0          40  7 \n",
      "\n",
      "PPV: 0.00 \n",
      "\n",
      "3 cluster model\n",
      "\n",
      "No cluster 3 data.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Greg\\anaconda3\\lib\\site-packages\\sklearn\\base.py:488: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names must be in the same order as they were in fit.\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\Greg\\anaconda3\\lib\\site-packages\\sklearn\\base.py:488: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names must be in the same order as they were in fit.\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "classify_ext_data(\"moe_ef_gh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors: ['s_score', 'Hits', 'max_feat', 'avg_feat', 'max_centr', 'min_centr', 'avg_centr', 'features', 'all_same', 'hyd_prop', 'don_prop', 'catdon_prop', 'hydaro_prop', 'aniacc_prop'] \n",
      "\n",
      "score based Q ph4s: 27 \n",
      "\n",
      "0 cluster model\n",
      "\n",
      "No cluster 0 data.\n",
      "\n",
      "1 cluster model\n",
      "\n",
      "Predicted   0   1\n",
      "Actual           \n",
      "0          61  48\n",
      "1          11  16 \n",
      "\n",
      "PPV: 0.25 \n",
      "\n",
      "2 cluster model\n",
      "\n",
      "Predicted   0   1\n",
      "Actual           \n",
      "0          72  10 \n",
      "\n",
      "PPV: 0.00 \n",
      "\n",
      "3 cluster model\n",
      "\n",
      "No cluster 3 data.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Greg\\anaconda3\\lib\\site-packages\\sklearn\\base.py:488: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names must be in the same order as they were in fit.\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\Greg\\anaconda3\\lib\\site-packages\\sklearn\\base.py:488: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names must be in the same order as they were in fit.\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "classify_ext_data(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors: ['s_score', 'Hits', 'max_feat', 'avg_feat', 'max_centr', 'min_centr', 'avg_centr', 'features', 'all_same', 'hyd_prop', 'don_prop', 'catdon_prop', 'hydaro_prop', 'aniacc_prop'] \n",
      "\n",
      "score based Q ph4s: 5 \n",
      "\n",
      "0 cluster model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Greg\\anaconda3\\lib\\site-packages\\sklearn\\base.py:488: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names must be in the same order as they were in fit.\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\Greg\\anaconda3\\lib\\site-packages\\sklearn\\base.py:488: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names must be in the same order as they were in fit.\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No cluster 0 data.\n",
      "\n",
      "1 cluster model\n",
      "\n",
      "Predicted  0   1\n",
      "Actual          \n",
      "0          7  11\n",
      "1          1   4 \n",
      "\n",
      "PPV: 0.27 \n",
      "\n",
      "2 cluster model\n",
      "\n",
      "Predicted   0  1\n",
      "Actual          \n",
      "0          17  3 \n",
      "\n",
      "PPV: 0.00 \n",
      "\n",
      "3 cluster model\n",
      "\n",
      "No cluster 3 data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classify_ext_data(\"moe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors: ['s_score', 'Hits', 'max_feat', 'avg_feat', 'max_centr', 'min_centr', 'avg_centr', 'features', 'all_same', 'hyd_prop', 'don_prop', 'catdon_prop', 'hydaro_prop', 'aniacc_prop'] \n",
      "\n",
      "score based Q ph4s: 6 \n",
      "\n",
      "0 cluster model\n",
      "\n",
      "No cluster 0 data.\n",
      "\n",
      "1 cluster model\n",
      "\n",
      "Predicted   0  1\n",
      "Actual          \n",
      "0          15  9\n",
      "1           2  4 \n",
      "\n",
      "PPV: 0.31 \n",
      "\n",
      "2 cluster model\n",
      "\n",
      "Predicted   0  1\n",
      "Actual          \n",
      "0          10  2 \n",
      "\n",
      "PPV: 0.00 \n",
      "\n",
      "3 cluster model\n",
      "\n",
      "Predicted  0\n",
      "Actual      \n",
      "0          2 \n",
      "\n",
      "PPV: nan \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Greg\\anaconda3\\lib\\site-packages\\sklearn\\base.py:488: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names must be in the same order as they were in fit.\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\Greg\\anaconda3\\lib\\site-packages\\sklearn\\base.py:488: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names must be in the same order as they were in fit.\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\Greg\\anaconda3\\lib\\site-packages\\sklearn\\base.py:488: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names must be in the same order as they were in fit.\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "<ipython-input-103-d33edd79f23c>:160: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  PPV = (TP / (TP + FP))\n"
     ]
    }
   ],
   "source": [
    "classify_ext_data(\"EF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors: ['s_score', 'Hits', 'max_feat', 'avg_feat', 'max_centr', 'min_centr', 'avg_centr', 'features', 'all_same', 'hyd_prop', 'don_prop', 'catdon_prop', 'hydaro_prop', 'aniacc_prop'] \n",
      "\n",
      "score based Q ph4s: 8 \n",
      "\n",
      "0 cluster model\n",
      "\n",
      "No cluster 0 data.\n",
      "\n",
      "1 cluster model\n",
      "\n",
      "Predicted  0  1\n",
      "Actual         \n",
      "0          9  1 \n",
      "\n",
      "PPV: 0.00 \n",
      "\n",
      "2 cluster model\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Greg\\anaconda3\\lib\\site-packages\\sklearn\\base.py:488: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names must be in the same order as they were in fit.\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\Greg\\anaconda3\\lib\\site-packages\\sklearn\\base.py:488: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names must be in the same order as they were in fit.\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted   0   1\n",
      "Actual           \n",
      "0          19  13\n",
      "1           2   6 \n",
      "\n",
      "PPV: 0.32 \n",
      "\n",
      "3 cluster model\n",
      "\n",
      "No cluster 3 data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classify_ext_data(\"GH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors: ['s_score', 'Hits', 'max_feat', 'avg_feat', 'max_centr', 'min_centr', 'avg_centr', 'features', 'all_same', 'hyd_prop', 'don_prop', 'catdon_prop', 'hydaro_prop', 'aniacc_prop'] \n",
      "\n",
      "score based Q ph4s: 4 \n",
      "\n",
      "0 cluster model\n",
      "\n",
      "No cluster 0 data.\n",
      "\n",
      "1 cluster model\n",
      "\n",
      "Predicted   0  1\n",
      "Actual          \n",
      "0          10  8 \n",
      "\n",
      "PPV: 0.00 \n",
      "\n",
      "2 cluster model\n",
      "\n",
      "Predicted  0   1\n",
      "Actual          \n",
      "0          8  12\n",
      "1          1   3 \n",
      "\n",
      "PPV: 0.20 \n",
      "\n",
      "3 cluster model\n",
      "\n",
      "No cluster 3 data.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Greg\\anaconda3\\lib\\site-packages\\sklearn\\base.py:488: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names must be in the same order as they were in fit.\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\Greg\\anaconda3\\lib\\site-packages\\sklearn\\base.py:488: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names must be in the same order as they were in fit.\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "classify_ext_data(\"rec_ef\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors: ['s_score', 'Hits', 'max_feat', 'avg_feat', 'max_centr', 'min_centr', 'avg_centr', 'features', 'all_same', 'hyd_prop', 'don_prop', 'catdon_prop', 'hydaro_prop', 'aniacc_prop'] \n",
      "\n",
      "score based Q ph4s: 4 \n",
      "\n",
      "0 cluster model\n",
      "\n",
      "No cluster 0 data.\n",
      "\n",
      "1 cluster model\n",
      "\n",
      "Predicted   0  1\n",
      "Actual          \n",
      "0          13  4 \n",
      "\n",
      "PPV: 0.00 \n",
      "\n",
      "2 cluster model\n",
      "\n",
      "Predicted  0   1\n",
      "Actual          \n",
      "0          2  18\n",
      "1          1   2 \n",
      "\n",
      "PPV: 0.10 \n",
      "\n",
      "3 cluster model\n",
      "\n",
      "No cluster 3 data.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Greg\\anaconda3\\lib\\site-packages\\sklearn\\base.py:488: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names must be in the same order as they were in fit.\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\Greg\\anaconda3\\lib\\site-packages\\sklearn\\base.py:488: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names must be in the same order as they were in fit.\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "classify_ext_data(\"rec_gh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save models\n",
    "#import joblib\n",
    "#from joblib import dump, load\n",
    "\n",
    "#joblib.dump(sgdc0 , 'model_sgdc0')\n",
    "#joblib.dump(sgdc0 , 'model_sgdc1')\n",
    "#joblib.dump(sgdc0 , 'model_sgdc2')\n",
    "#joblib.dump(sgdc0 , 'model_sgdc3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
