{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import preprocessing, neighbors\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "from typing import Tuple\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import pandas as pd\n",
    "import random, os\n",
    "import csv\n",
    "\n",
    "rng = 1\n",
    "\n",
    "def seed_everything(seed=1):\n",
    "    \"\"\"\"\n",
    "    Seed everything.\n",
    "    \"\"\"   \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "#print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster test/train data\n",
    "def get_clusters(X_train: pd.DataFrame, X_test: pd.DataFrame, n_clusters: int) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    applies k-means clustering to training data to find clusters and predicts them for the test set\n",
    "    \"\"\"\n",
    "    clustering = KMeans(n_clusters=n_clusters, random_state=rng)\n",
    "    clustering.fit(X_train)\n",
    "    # apply the labels to the training set\n",
    "    train_labels = clustering.labels_\n",
    "    X_train_clstrs = X_train.copy()\n",
    "    X_train_clstrs['clusters'] = train_labels\n",
    "    \n",
    "    #write ext_clusters to csv\n",
    "    X_train_clstrs.to_csv('X_train_clstrs.csv')\n",
    "    \n",
    "    # predict labels on the test set\n",
    "    test_labels = clustering.predict(X_test)\n",
    "    X_test_clstrs = X_test.copy()\n",
    "    X_test_clstrs['clusters'] = test_labels\n",
    "    return X_train_clstrs, X_test_clstrs\n",
    "\n",
    "#scale each feature\n",
    "def scale_features(X_train: pd.DataFrame, X_test: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    applies standard scaler (z-scores) to training data and predicts z-scores for the test set\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    to_scale = [col for col in X_train.columns.values]\n",
    "    scaler.fit(X_train[to_scale])\n",
    "    X_train[to_scale] = scaler.transform(X_train[to_scale])\n",
    "    \n",
    "    # predict z-scores on the test set\n",
    "    X_test[to_scale] = scaler.transform(X_test[to_scale])\n",
    "    \n",
    "    return X_train, X_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors: ['Hits', 'max_feat', 'avg_feat', 'max_centr', 'min_centr', 'avg_centr', 'features', 'all_same', 's_score', 'hyd_prop', 'don_prop', 'catdon_prop', 'hydaro_prop', 'aniacc_prop'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('..\\..\\data\\_All_Receptors_runs_1_2_3_binary.csv')\n",
    "df.drop(['min_feat','receptor','Active_Rate','Enrichment', 'GH', 'Actives', 'filename', 'fbase', 'hyd', 'don', 'acc', 'ani', 'cat', 'aro', 'donhyd', 'catdon', 'hydaro', 'aniacc', 'donacc', 'acc_prop', 'ani_prop', 'cat_prop', 'aro_prop', 'donhyd_prop', 'donacc_prop'], axis=1, inplace=True)\n",
    "df.fillna(-99999)\n",
    "\n",
    "predictors = list(df.columns)\n",
    "predictors = predictors[:-1]\n",
    "\n",
    "print('Predictors:', predictors,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors: ['Hits', 'max_feat', 'avg_feat', 'max_centr', 'min_centr', 'avg_centr', 'features', 'all_same', 's_score', 'hyd_prop', 'don_prop', 'catdon_prop', 'hydaro_prop', 'aniacc_prop'] \n",
      "\n",
      "x_train Q ph4s: 2699 \n",
      "\n",
      "x_test Q ph4s: 922 \n",
      "\n",
      "[-2.261291652098838, -0.6232776848498619, 1.0147362823991142, 2.65275024964809]\n",
      "X_train 0/1/2/3 cluster values\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "[-2.26129165]\n",
      "[-0.62327768]\n",
      "[1.01473628]\n",
      "[2.65275025] \n",
      "\n",
      "0 cluster model\n",
      "\n",
      "Predicted   0   1\n",
      "Actual           \n",
      "0          34  14\n",
      "1          56  54 \n",
      "\n",
      "PPV: 0.79 \n",
      "\n",
      "1 cluster model\n",
      "\n",
      "Predicted    0    1\n",
      "Actual             \n",
      "0          577  212\n",
      "1           79  542 \n",
      "\n",
      "PPV: 0.72\n",
      "2 cluster model\n",
      "\n",
      "Predicted    0    1\n",
      "Actual             \n",
      "0          865   80\n",
      "1            5  169 \n",
      "\n",
      "PPV: 0.68 \n",
      "\n",
      "3 cluster model\n",
      "\n",
      "Predicted  0   1\n",
      "Actual          \n",
      "0          5   7\n",
      "1          1  16 \n",
      "\n",
      "PPV: 0.70\n"
     ]
    }
   ],
   "source": [
    "#read in train/test data\n",
    "df = pd.read_csv('..\\..\\data\\_All_Receptors_runs_1_2_3_binary.csv')\n",
    "df = df[['Hits', 'max_feat', 'avg_feat', 'max_centr', 'min_centr', 'avg_centr', 'features', 'all_same', 's_score', 'hyd_prop', 'don_prop', 'catdon_prop', 'hydaro_prop', 'aniacc_prop', 'quality']]\n",
    "df.fillna(-99999)\n",
    "\n",
    "predictors = list(df.columns)\n",
    "predictors = predictors[:-1]\n",
    "\n",
    "print('Predictors:', predictors,'\\n')\n",
    "\n",
    "\n",
    "#split data into quality/not quality sets\n",
    "q_ph4s = df[df['quality'] == 1]\n",
    "nq_ph4s = df[df['quality'] != 1]\n",
    "\n",
    "#ensure that there is an equal number of nq ph4s\n",
    "nq_ph4s = nq_ph4s.sample(n=2*len(q_ph4s), random_state = rng)\n",
    "#print(type(nq_ph4s))\n",
    "#print(nq_ph4s['Hits'].head())\n",
    "#print(nq_ph4s['Hits'].tail())\n",
    "\n",
    "#merge arrays prior to TTS\n",
    "frames = [q_ph4s, nq_ph4s]\n",
    "df = pd.concat(frames)\n",
    "\n",
    "#x is features, y is classes\n",
    "x = df.drop('quality', axis=1)\n",
    "y = df.quality\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=rng)\n",
    "\n",
    "print(\"x_train Q ph4s:\", y_train.sum(),'\\n')\n",
    "print(\"x_test Q ph4s:\",y_test.sum(),'\\n')\n",
    "\n",
    "X_train_clstrs, X_test_clstrs = get_clusters(x_train, x_test, 4)\n",
    "\n",
    "X_train_scaled, X_test_scaled = scale_features(X_train_clstrs, X_test_clstrs)\n",
    "\n",
    "#print(X_train_scaled)\n",
    "\n",
    "# to divide the df by cluster, we need to ensure we use the correct class labels, we'll use pandas to do that\n",
    "train_clusters = X_train_scaled.copy()\n",
    "test_clusters = X_test_scaled.copy()\n",
    "train_clusters['y'] = y_train\n",
    "test_clusters['y'] = y_test\n",
    "\n",
    "uniq_clusters = train_clusters['clusters'].unique()\n",
    "uniqs = uniq_clusters.tolist()\n",
    "uniqs.sort()\n",
    "print(uniqs)\n",
    "\n",
    "#print(y_train)\n",
    "#print(train_clusters['clusters'])\n",
    "\n",
    "#print(type(clusters))\n",
    "#print(type(train_clusters['clusters']))\n",
    "#frames = [clusters, train_clusters['clusters']]\n",
    "#df = pd.concat(frames, axis=1)\n",
    "#print(type(df))\n",
    "#print(df)\n",
    "#df.to_csv('4clusters.csv')\n",
    "\n",
    "# locate the \"0\" cluster\n",
    "train_0 = train_clusters.loc[train_clusters.clusters <= uniqs[0]] # after scaling, 0 went to -2.187\n",
    "test_0 = test_clusters.loc[test_clusters.clusters <= uniqs[0]]\n",
    "y_train_0 = train_0.y.values\n",
    "y_test_0 = test_0.y.values\n",
    "# locate the \"1\" cluster\n",
    "train_1 = train_clusters.loc[(train_clusters.clusters <= uniqs[1]) & (train_clusters.clusters > uniqs[0])] # after scaling, 1 went to -0.62\n",
    "test_1 = test_clusters.loc[(test_clusters.clusters <= uniqs[1]) & (test_clusters.clusters > uniqs[0])]\n",
    "y_train_1 = train_1.y.values\n",
    "y_test_1 = test_1.y.values\n",
    "\n",
    "# locate the \"2\" cluster\n",
    "train_2 = train_clusters.loc[(train_clusters.clusters <= uniqs[2]) & (train_clusters.clusters > uniqs[1])] # after scaling, 2 went to 0.945\n",
    "test_2 = test_clusters.loc[(test_clusters.clusters <= uniqs[2]) & (test_clusters.clusters > uniqs[1])]\n",
    "y_train_2 = train_2.y.values\n",
    "y_test_2 = test_2.y.values\n",
    "\n",
    "# locate the \"3\" cluster\n",
    "train_3 = train_clusters.loc[train_clusters.clusters >= uniqs[3]] # after scaling, 3 went to 2.51\n",
    "test_3 = test_clusters.loc[test_clusters.clusters >= uniqs[3]]\n",
    "y_train_3 = train_3.y.values\n",
    "y_test_3 = test_3.y.values\n",
    "\n",
    "# drop the targets from the training set\n",
    "X_train_0 = train_0.drop(columns=['y'])\n",
    "X_test_0 = test_0.drop(columns=['y'])\n",
    "X_train_1 = train_1.drop(columns=['y'])\n",
    "X_test_1 = test_1.drop(columns=['y'])\n",
    "X_train_2 = train_2.drop(columns=['y'])\n",
    "X_test_2 = test_2.drop(columns=['y'])\n",
    "X_train_3 = train_3.drop(columns=['y'])\n",
    "X_test_3 = test_3.drop(columns=['y'])\n",
    "\n",
    "print('X_train 0/1/2/3 cluster values\\n')\n",
    "print('-------------------------------\\n')\n",
    "print(X_train_0['clusters'].unique())\n",
    "print(X_train_1['clusters'].unique())\n",
    "print(X_train_2['clusters'].unique())\n",
    "print(X_train_3['clusters'].unique(),'\\n')\n",
    "\n",
    "#print(X_train_0)\n",
    "#print(len(X_test_1))\n",
    "\n",
    "\n",
    "#0 cluster LR model\n",
    "sgdc0 = SGDClassifier(loss=\"log\", penalty=\"l1\", max_iter=1000, tol=1e-2, class_weight='balanced', random_state = rng)\n",
    "sgdc0.fit(X_train_0, y_train_0)\n",
    "\n",
    "y_pred = (sgdc0.predict(X_test_0))\n",
    "confmat = confusion_matrix(y_test_0, y_pred, labels=[0,1])\n",
    "#print(confmat)\n",
    "\n",
    "confmat = confusion_matrix(y_test_0, y_pred, labels=[0,1]).ravel()\n",
    "FP = (confmat[1])\n",
    "TP = (confmat[3])\n",
    "\n",
    "PPV = (TP / (TP + FP))\n",
    "\n",
    "cm = pd.crosstab(y_test_0, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=False)\n",
    "\n",
    "print('0 cluster model\\n')\n",
    "print(cm,'\\n')\n",
    "\n",
    "print('PPV:', format(PPV, '.2f'),'\\n')\n",
    "\n",
    "#1 cluster LR model\n",
    "sgdc1 = SGDClassifier(loss=\"log\", penalty=\"l1\", max_iter=1000, tol=1e-2, class_weight='balanced', random_state = rng)\n",
    "sgdc1.fit(X_train_1, y_train_1)\n",
    "\n",
    "y_pred = (sgdc1.predict(X_test_1))\n",
    "confmat = confusion_matrix(y_test_1, y_pred, labels=[0,1])\n",
    "\n",
    "confmat = confusion_matrix(y_test_1, y_pred, labels=[0,1]).ravel()\n",
    "FP = (confmat[1])\n",
    "TP = (confmat[3])\n",
    "\n",
    "PPV = (TP / (TP + FP))\n",
    "\n",
    "cm = pd.crosstab(y_test_1, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=False)\n",
    "\n",
    "print('1 cluster model\\n')\n",
    "print(cm,'\\n')\n",
    "\n",
    "print('PPV:', format(PPV, '.2f'))\n",
    "\n",
    "#print(X_train_0)\n",
    "#print(len(X_train_2))\n",
    "\n",
    "#2 cluster LR model\n",
    "sgdc2 = SGDClassifier(loss=\"log\", penalty=\"l1\", max_iter=1000, tol=1e-2, class_weight='balanced', random_state = rng)\n",
    "sgdc2.fit(X_train_2, y_train_2)\n",
    "\n",
    "y_pred = (sgdc2.predict(X_test_2))\n",
    "confmat = confusion_matrix(y_test_2, y_pred, labels=[0,1])\n",
    "#print(confmat)\n",
    "\n",
    "confmat = confusion_matrix(y_test_2, y_pred, labels=[0,1]).ravel()\n",
    "FP = (confmat[1])\n",
    "TP = (confmat[3])\n",
    "\n",
    "PPV = (TP / (TP + FP))\n",
    "\n",
    "cm = pd.crosstab(y_test_2, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=False)\n",
    "\n",
    "print('2 cluster model\\n')\n",
    "print(cm,'\\n')\n",
    "\n",
    "print('PPV:', format(PPV, '.2f'),'\\n')\n",
    "\n",
    "#3 cluster LR model\n",
    "sgdc3 = SGDClassifier(loss=\"log\", penalty=\"l1\", max_iter=1000, tol=1e-2, class_weight='balanced', random_state = rng)\n",
    "sgdc3.fit(X_train_3, y_train_3)\n",
    "\n",
    "y_pred = (sgdc3.predict(X_test_3))\n",
    "confmat = confusion_matrix(y_test_3, y_pred, labels=[0,1])\n",
    "#print(confmat)\n",
    "\n",
    "confmat = confusion_matrix(y_test_3, y_pred, labels=[0,1]).ravel()\n",
    "FP = (confmat[1])\n",
    "TP = (confmat[3])\n",
    "\n",
    "PPV = (TP / (TP + FP))\n",
    "\n",
    "cm = pd.crosstab(y_test_3, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=False)\n",
    "\n",
    "print('3 cluster model\\n')\n",
    "print(cm,'\\n')\n",
    "\n",
    "print('PPV:', format(PPV, '.2f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def scale_features_single(X: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    applies standard scaler (z-scores) to training data and predicts z-scores for the test set\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    to_scale = [col for col in X.columns.values]\n",
    "    scaler.fit(X[to_scale])\n",
    "    X[to_scale] = scaler.transform(X[to_scale])\n",
    "    \n",
    "    return X\n",
    "      \n",
    "def classify_ext_data(input_csv, subset = \"none\"):      \n",
    "    ext_df = pd.read_csv(input_csv)\n",
    "    ext_df.fillna(-99999)\n",
    "    receptors = ext_df.Receptor\n",
    "    hits_actual = ext_df.Hits\n",
    "    score_types = ext_df['Score Type']\n",
    "    subsets = ext_df.subset\n",
    "    init_ext_df = ext_df\n",
    "    \n",
    "    #check if a 'quality' column exists. one will not exist if classifying data with unknown enrichments.\n",
    "    if 'quality' not in ext_df:\n",
    "        ext_df = ext_df[['s_score','Hits', 'max_feat', 'avg_feat', 'max_centr', 'min_centr', 'avg_centr', 'features', 'all_same', 'hyd_prop', 'don_prop', 'catdon_prop', 'hydaro_prop', 'aniacc_prop']]\n",
    "        x = ext_df\n",
    "    else:\n",
    "        ext_df = ext_df[['s_score','Hits', 'max_feat', 'avg_feat', 'max_centr', 'min_centr', 'avg_centr', 'features', 'all_same', 'hyd_prop', 'don_prop', 'catdon_prop', 'hydaro_prop', 'aniacc_prop', 'quality']]   \n",
    "        x = ext_df.drop('quality', axis=1)\n",
    "        y = ext_df.quality\n",
    "    \n",
    "    predictors = list(ext_df.columns)\n",
    "    predictors = predictors[:-1]\n",
    "    print('Predictors:', predictors,'\\n')\n",
    "    \n",
    "    if 'quality' in init_ext_df:\n",
    "        print(\"score based Q ph4s:\", y.sum(),'\\n')\n",
    "    \n",
    "    #cluster training data\n",
    "    clustering = KMeans(n_clusters=4, random_state=rng)\n",
    "    clustering.fit(x_train)\n",
    "    # apply the labels to the training set\n",
    "    train_labels = clustering.labels_\n",
    "    X_train_clstrs = x_train.copy()\n",
    "    X_train_clstrs['clusters'] = train_labels\n",
    "    \n",
    "    # predict labels on the external set\n",
    "    ext_labels = clustering.predict(x)\n",
    "    X_clstrs = x.copy()\n",
    "    X_clstrs['clusters'] = ext_labels\n",
    "    \n",
    "    X_scaled = scale_features_single(X_clstrs)\n",
    "    ext_clusters = X_scaled.copy()\n",
    "    if 'quality' in init_ext_df:\n",
    "        ext_clusters['y'] = y\n",
    "    \n",
    "    #add receptors, hits_actual, score type, and subset columns back prior to 0/1/2/3 split\n",
    "    ext_clusters['Receptor'] = receptors\n",
    "    ext_clusters['hits_actual'] = hits_actual\n",
    "    ext_clusters['Score Type'] = score_types\n",
    "    ext_clusters['subset'] = subsets\n",
    "    \n",
    "    #write ext_clusters to csv\n",
    "    X_train_clstrs.to_csv('X_train_clstrs2.csv')\n",
    "    \n",
    "    # locate the \"0\" cluster\n",
    "    ext_0 = ext_clusters.loc[ext_clusters.clusters <= uniqs[0]] # after scaling, 0 went negtive\n",
    "    if 'quality' in init_ext_df:\n",
    "        y_ext_0 = ext_0.y.values\n",
    "    ext_0_receptors = ext_0.Receptor\n",
    "    ext_0_hits_actual = ext_0.hits_actual\n",
    "    ext_0_score_types = ext_0['Score Type']\n",
    "    ext_0_subsets = ext_0.subset\n",
    "    \n",
    "    # locate the \"1\" cluster\n",
    "    ext_1 = ext_clusters.loc[(ext_clusters.clusters <= uniqs[1]) & (ext_clusters.clusters > uniqs[0])] # after scaling, 0 went negtive\n",
    "    if 'quality' in init_ext_df:\n",
    "        y_ext_1 = ext_1.y.values\n",
    "    ext_1_receptors = ext_1.Receptor\n",
    "    ext_1_hits_actual = ext_1.hits_actual\n",
    "    ext_1_score_types = ext_1['Score Type']\n",
    "    ext_1_subsets = ext_1.subset\n",
    "    \n",
    "    # locate the \"2\" cluster\n",
    "    ext_2 = ext_clusters.loc[(ext_clusters.clusters <= uniqs[2]) & (ext_clusters.clusters > uniqs[1])] # after scaling, 0 went negtive\n",
    "    if 'quality' in init_ext_df:\n",
    "        y_ext_2 = ext_2.y.values\n",
    "    ext_2_receptors = ext_2.Receptor\n",
    "    ext_2_hits_actual = ext_2.hits_actual\n",
    "    ext_2_score_types = ext_2['Score Type']\n",
    "    ext_2_subsets = ext_2.subset\n",
    "    \n",
    "    # locate the \"3\" cluster\n",
    "    ext_3 = ext_clusters.loc[ext_clusters.clusters > uniqs[3] ] # after scaling, 0 went negtive\n",
    "    if 'quality' in init_ext_df:\n",
    "        y_ext_3 = ext_3.y.values\n",
    "    ext_3_receptors = ext_3.Receptor\n",
    "    ext_3_hits_actual = ext_3.hits_actual\n",
    "    ext_3_score_types = ext_3['Score Type']\n",
    "    ext_3_subsets = ext_3.subset\n",
    "\n",
    "    # drop the targets from each external set (if classifying known external data)\n",
    "    if 'quality' in init_ext_df:\n",
    "        X_ext_0 = ext_0.drop(columns=['y', 'Receptor', 'hits_actual', 'Score Type', 'subset'])\n",
    "        X_ext_1 = ext_1.drop(columns=['y', 'Receptor', 'hits_actual', 'Score Type', 'subset'])\n",
    "        X_ext_2 = ext_2.drop(columns=['y', 'Receptor', 'hits_actual', 'Score Type', 'subset'])\n",
    "        X_ext_3 = ext_3.drop(columns=['y', 'Receptor', 'hits_actual', 'Score Type', 'subset'])\n",
    "    else:\n",
    "        X_ext_0 = ext_0.drop(columns=['Receptor', 'hits_actual', 'Score Type', 'subset'])\n",
    "        X_ext_1 = ext_1.drop(columns=['Receptor', 'hits_actual', 'Score Type', 'subset'])\n",
    "        X_ext_2 = ext_2.drop(columns=['Receptor', 'hits_actual', 'Score Type', 'subset'])\n",
    "        X_ext_3 = ext_3.drop(columns=['Receptor', 'hits_actual', 'Score Type', 'subset'])\n",
    "    \n",
    "    # drop receptor column from each external set\n",
    "    \n",
    "    #print(len(X_ext_0))\n",
    "    #print(len(X_ext_1))\n",
    "    #print(len(X_ext_2))\n",
    "    #print(len(X_ext_3))\n",
    "    \n",
    "    #predict based on 0 cluster model\n",
    "    print('0 cluster model\\n')\n",
    "    print('---------------\\n')\n",
    "    if len(X_ext_0) == 0:\n",
    "        print('No cluster 0 data.\\n')\n",
    "    else:\n",
    "        y_pred = (sgdc0.predict(X_ext_0))\n",
    "        if 'quality' in init_ext_df:\n",
    "            confmat = confusion_matrix(y_ext_0, y_pred, labels=[0,1])\n",
    "            confmat = confusion_matrix(y_ext_0, y_pred, labels=[0,1]).ravel()\n",
    "            FP = (confmat[1])\n",
    "            TP = (confmat[3])\n",
    "            PPV = (TP / (TP + FP))\n",
    "            cm = pd.crosstab(y_ext_0, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=False)\n",
    "            print(cm,'\\n')\n",
    "            print('PPV:', format(PPV, '.2f'),'\\n')\n",
    "        \n",
    "        X_ext_0['Receptor'] = ext_0_receptors\n",
    "        X_ext_0['hits_actual'] = ext_0_hits_actual\n",
    "        X_ext_0['Score Type'] = ext_0_score_types\n",
    "        X_ext_0['subset'] = ext_0_subsets\n",
    "        if 'quality' in init_ext_df:\n",
    "            X_ext_0['quality'] = y_ext_0\n",
    "        \n",
    "        X_ext_0['quality_pred'] = y_pred\n",
    "        if 'quality' in init_ext_df:\n",
    "            X_ext_0.to_csv('results/'+subset+'/0cluster_results.csv')\n",
    "        #if classifying unknown external data, print the ph4s classified as quality and write them to .csv\n",
    "        if 'quality' not in init_ext_df:\n",
    "            print(X_ext_0.loc[X_ext_0['quality_pred'] == 1], '\\n')\n",
    "            ph4_preds = X_ext_0.loc[X_ext_0['quality_pred'] == 1]\n",
    "            ph4_preds.to_csv('0cluster_ph4_preds.csv')\n",
    "\n",
    "    print('1 cluster model\\n')\n",
    "    print('---------------\\n')\n",
    "    if len(X_ext_1) == 0:\n",
    "        print('No cluster 1 data.\\n')\n",
    "    else:\n",
    "        y_pred = (sgdc1.predict(X_ext_1))\n",
    "        if 'quality' in init_ext_df:\n",
    "            confmat = confusion_matrix(y_ext_1, y_pred, labels=[0,1])\n",
    "            confmat = confusion_matrix(y_ext_1, y_pred, labels=[0,1]).ravel()\n",
    "            FP = (confmat[1])\n",
    "            TP = (confmat[3])\n",
    "            PPV = (TP / (TP + FP))\n",
    "            cm = pd.crosstab(y_ext_1, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=False)\n",
    "            print(cm,'\\n')\n",
    "            print('PPV:', format(PPV, '.2f'),'\\n')\n",
    "        \n",
    "        X_ext_1['Receptor'] = ext_1_receptors\n",
    "        X_ext_1['hits_actual'] = ext_1_hits_actual\n",
    "        X_ext_1['Score Type'] = ext_1_score_types\n",
    "        X_ext_1['subset'] = ext_1_subsets\n",
    "        if 'quality' in init_ext_df:\n",
    "            X_ext_1['quality'] = y_ext_1\n",
    "        \n",
    "        X_ext_1['quality_pred'] = y_pred\n",
    "        if 'quality' in init_ext_df:\n",
    "            X_ext_1.to_csv('results/'+subset+'/1cluster_results.csv')\n",
    "            \n",
    "        if 'quality' not in init_ext_df:\n",
    "            print(X_ext_1.loc[X_ext_1['quality_pred'] == 1], '\\n')\n",
    "            ph4_preds = X_ext_1.loc[X_ext_1['quality_pred'] == 1]\n",
    "            ph4_preds.to_csv('1cluster_ph4_preds.csv')\n",
    "        \n",
    "    print('2 cluster model\\n')\n",
    "    print('---------------\\n')\n",
    "    if len(X_ext_2) == 0:\n",
    "        print('No cluster 2 data.\\n')\n",
    "    else:\n",
    "        y_pred = (sgdc2.predict(X_ext_2))\n",
    "        if 'quality' in init_ext_df:\n",
    "            confmat = confusion_matrix(y_ext_2, y_pred, labels=[0,1])\n",
    "            confmat = confusion_matrix(y_ext_2, y_pred, labels=[0,1]).ravel()\n",
    "            FP = (confmat[1])\n",
    "            TP = (confmat[3])\n",
    "            PPV = (TP / (TP + FP))\n",
    "            cm = pd.crosstab(y_ext_2, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=False)\n",
    "            print(cm,'\\n')\n",
    "            print('PPV:', format(PPV, '.2f'),'\\n')\n",
    "        \n",
    "        X_ext_2['Receptor'] = ext_2_receptors\n",
    "        X_ext_2['hits_actual'] = ext_2_hits_actual\n",
    "        X_ext_2['Score Type'] = ext_2_score_types\n",
    "        X_ext_2['subset'] = ext_2_subsets\n",
    "        if 'quality' in init_ext_df:\n",
    "            X_ext_2['quality'] = y_ext_2\n",
    "        \n",
    "        X_ext_2['quality_pred'] = y_pred\n",
    "        if 'quality' in init_ext_df:\n",
    "            X_ext_2.to_csv('results/'+subset+'/2cluster_results.csv')\n",
    "        \n",
    "        if 'quality' not in init_ext_df:\n",
    "            print(X_ext_2.loc[X_ext_2['quality_pred'] == 1], '\\n')\n",
    "            ph4_preds = X_ext_2.loc[X_ext_2['quality_pred'] == 1]\n",
    "            ph4_preds.to_csv('2cluster_ph4_preds.csv')\n",
    "        \n",
    "    print('3 cluster model\\n')\n",
    "    print('---------------\\n')\n",
    "    if len(X_ext_3) == 0:\n",
    "        print('No cluster 3 data.\\n')\n",
    "    else:\n",
    "        y_pred = (sgdc3.predict(X_ext_3))\n",
    "        if 'quality' in init_ext_df:\n",
    "            confmat = confusion_matrix(y_ext_3, y_pred, labels=[0,1])\n",
    "            confmat = confusion_matrix(y_ext_3, y_pred, labels=[0,1]).ravel()\n",
    "            FP = (confmat[1])\n",
    "            TP = (confmat[3])\n",
    "            PPV = (TP / (TP + FP))\n",
    "            cm = pd.crosstab(y_ext_3, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=False)\n",
    "            print(cm,'\\n')\n",
    "            print('PPV:', format(PPV, '.2f'),'\\n')\n",
    "        \n",
    "        X_ext_3['Receptor'] = ext_3_receptors\n",
    "        X_ext_3['hits_actual'] = ext_3_hits_actual\n",
    "        X_ext_3['Score Type'] = ext_3_score_types\n",
    "        X_ext_3['subset'] = ext_3_subsets\n",
    "        if 'quality' in init_ext_df:\n",
    "            X_ext_3['quality'] = y_ext_3\n",
    "        \n",
    "        X_ext_3['quality_pred'] = y_pred\n",
    "        \n",
    "        if 'quality' in init_ext_df:\n",
    "            X_ext_3.to_csv('results/'+subset+'/3cluster_results.csv')\n",
    "        \n",
    "        if 'quality' not in init_ext_df:\n",
    "            print(X_ext_3.loc[X_ext_3['quality_pred'] == 1], '\\n')\n",
    "            ph4_preds = X_ext_3.loc[X_ext_3['quality_pred'] == 1]\n",
    "            ph4_preds.to_csv('3cluster_ph4_preds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors: ['s_score', 'Hits', 'max_feat', 'avg_feat', 'max_centr', 'min_centr', 'avg_centr', 'features', 'all_same', 'hyd_prop', 'don_prop', 'catdon_prop', 'hydaro_prop', 'aniacc_prop'] \n",
      "\n",
      "score based Q ph4s: 85 \n",
      "\n",
      "0 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "No cluster 0 data.\n",
      "\n",
      "1 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "Predicted   0   1\n",
      "Actual           \n",
      "0          16   7\n",
      "1          26  26 \n",
      "\n",
      "PPV: 0.79 \n",
      "\n",
      "2 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "Predicted   0   1\n",
      "Actual           \n",
      "0          66  86\n",
      "1          15  18 \n",
      "\n",
      "PPV: 0.17 \n",
      "\n",
      "3 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "No cluster 3 data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classify_ext_data('..\\..\\data\\score_based_alldata_binary.csv', 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors: ['s_score', 'Hits', 'max_feat', 'avg_feat', 'max_centr', 'min_centr', 'avg_centr', 'features', 'all_same', 'hyd_prop', 'don_prop', 'catdon_prop', 'hydaro_prop', 'aniacc_prop'] \n",
      "\n",
      "score based Q ph4s: 16 \n",
      "\n",
      "0 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "No cluster 0 data.\n",
      "\n",
      "1 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "Predicted  0  1\n",
      "Actual         \n",
      "0          5  3\n",
      "1          5  7 \n",
      "\n",
      "PPV: 0.70 \n",
      "\n",
      "2 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "Predicted   0   1\n",
      "Actual           \n",
      "0          11  17\n",
      "1           2   2 \n",
      "\n",
      "PPV: 0.11 \n",
      "\n",
      "3 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "No cluster 3 data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classify_ext_data('..\\..\\data\\score_based_moefrags_data_binary.csv', 'moe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors: ['s_score', 'Hits', 'max_feat', 'avg_feat', 'max_centr', 'min_centr', 'avg_centr', 'features', 'all_same', 'hyd_prop', 'don_prop', 'catdon_prop', 'hydaro_prop', 'aniacc_prop'] \n",
      "\n",
      "score based Q ph4s: 20 \n",
      "\n",
      "0 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "No cluster 0 data.\n",
      "\n",
      "1 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "Predicted  0  1\n",
      "Actual         \n",
      "0          2  1\n",
      "1          5  4 \n",
      "\n",
      "PPV: 0.80 \n",
      "\n",
      "2 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "Predicted   0   1\n",
      "Actual           \n",
      "0          17  12\n",
      "1           4   7 \n",
      "\n",
      "PPV: 0.37 \n",
      "\n",
      "3 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "No cluster 3 data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classify_ext_data('..\\..\\data\\score_based_efdata_binary.csv', 'ef')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors: ['s_score', 'Hits', 'max_feat', 'avg_feat', 'max_centr', 'min_centr', 'avg_centr', 'features', 'all_same', 'hyd_prop', 'don_prop', 'catdon_prop', 'hydaro_prop', 'aniacc_prop'] \n",
      "\n",
      "score based Q ph4s: 21 \n",
      "\n",
      "0 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "No cluster 0 data.\n",
      "\n",
      "1 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "Predicted  0  1\n",
      "Actual         \n",
      "0          5  1\n",
      "1          9  6 \n",
      "\n",
      "PPV: 0.86 \n",
      "\n",
      "2 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "Predicted  0   1\n",
      "Actual          \n",
      "0          9  16\n",
      "1          2   4 \n",
      "\n",
      "PPV: 0.20 \n",
      "\n",
      "3 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "No cluster 3 data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classify_ext_data('..\\..\\data\\score_based_ghdata_binary.csv', 'gh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors: ['s_score', 'Hits', 'max_feat', 'avg_feat', 'max_centr', 'min_centr', 'avg_centr', 'features', 'all_same', 'hyd_prop', 'don_prop', 'catdon_prop', 'hydaro_prop', 'aniacc_prop'] \n",
      "\n",
      "score based Q ph4s: 13 \n",
      "\n",
      "0 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "No cluster 0 data.\n",
      "\n",
      "1 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "Predicted  0  1\n",
      "Actual         \n",
      "0          1  0\n",
      "1          4  4 \n",
      "\n",
      "PPV: 1.00 \n",
      "\n",
      "2 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "Predicted   0   1\n",
      "Actual           \n",
      "0          20  18\n",
      "1           1   4 \n",
      "\n",
      "PPV: 0.18 \n",
      "\n",
      "3 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "No cluster 3 data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classify_ext_data('..\\..\\data\\score_based_recefdata_binary.csv', 'rec_ef')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors: ['s_score', 'Hits', 'max_feat', 'avg_feat', 'max_centr', 'min_centr', 'avg_centr', 'features', 'all_same', 'hyd_prop', 'don_prop', 'catdon_prop', 'hydaro_prop', 'aniacc_prop'] \n",
      "\n",
      "score based Q ph4s: 15 \n",
      "\n",
      "0 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "No cluster 0 data.\n",
      "\n",
      "1 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "Predicted  0  1\n",
      "Actual         \n",
      "0          2  3\n",
      "1          4  4 \n",
      "\n",
      "PPV: 0.57 \n",
      "\n",
      "2 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "Predicted   0   1\n",
      "Actual           \n",
      "0          10  22\n",
      "1           6   1 \n",
      "\n",
      "PPV: 0.04 \n",
      "\n",
      "3 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "No cluster 3 data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classify_ext_data('..\\..\\data\\score_based_recghdata_binary.csv', 'rec_gh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors: ['s_score', 'Hits', 'max_feat', 'avg_feat', 'max_centr', 'min_centr', 'avg_centr', 'features', 'all_same', 'hyd_prop', 'don_prop', 'catdon_prop', 'hydaro_prop', 'aniacc_prop'] \n",
      "\n",
      "score based Q ph4s: 58 \n",
      "\n",
      "0 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "No cluster 0 data.\n",
      "\n",
      "1 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "Predicted   0   1\n",
      "Actual           \n",
      "0          10   1\n",
      "1          27  10 \n",
      "\n",
      "PPV: 0.91 \n",
      "\n",
      "2 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "Predicted   0    1\n",
      "Actual            \n",
      "0          73  118\n",
      "1          12    9 \n",
      "\n",
      "PPV: 0.07 \n",
      "\n",
      "3 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "No cluster 3 data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classify_ext_data('..\\..\\data\\hm_score_based_alldata_binary.csv', 'hm_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors: ['s_score', 'Hits', 'max_feat', 'avg_feat', 'max_centr', 'min_centr', 'avg_centr', 'features', 'all_same', 'hyd_prop', 'don_prop', 'catdon_prop', 'hydaro_prop', 'aniacc_prop'] \n",
      "\n",
      "score based Q ph4s: 9 \n",
      "\n",
      "0 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "No cluster 0 data.\n",
      "\n",
      "1 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "Predicted  0  1\n",
      "Actual         \n",
      "0          3  1\n",
      "1          4  1 \n",
      "\n",
      "PPV: 0.50 \n",
      "\n",
      "2 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "Predicted   0   1\n",
      "Actual           \n",
      "0          16  23\n",
      "1           2   2 \n",
      "\n",
      "PPV: 0.08 \n",
      "\n",
      "3 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "No cluster 3 data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classify_ext_data('..\\..\\data\\hm_score_based_moefrags_data_binary.csv', 'hm_moe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors: ['s_score', 'Hits', 'max_feat', 'avg_feat', 'max_centr', 'min_centr', 'avg_centr', 'features', 'all_same', 'hyd_prop', 'don_prop', 'catdon_prop', 'hydaro_prop', 'aniacc_prop'] \n",
      "\n",
      "score based Q ph4s: 11 \n",
      "\n",
      "0 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "No cluster 0 data.\n",
      "\n",
      "1 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "Predicted  0  1\n",
      "Actual         \n",
      "0          3  0\n",
      "1          5  2 \n",
      "\n",
      "PPV: 1.00 \n",
      "\n",
      "2 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "Predicted   0   1\n",
      "Actual           \n",
      "0          14  24\n",
      "1           2   2 \n",
      "\n",
      "PPV: 0.08 \n",
      "\n",
      "3 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "No cluster 3 data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classify_ext_data('..\\..\\data\\hm_score_based_efdata_binary.csv', 'hm_ef')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors: ['s_score', 'Hits', 'max_feat', 'avg_feat', 'max_centr', 'min_centr', 'avg_centr', 'features', 'all_same', 'hyd_prop', 'don_prop', 'catdon_prop', 'hydaro_prop', 'aniacc_prop'] \n",
      "\n",
      "score based Q ph4s: 11 \n",
      "\n",
      "0 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "No cluster 0 data.\n",
      "\n",
      "1 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "Predicted  0  1\n",
      "Actual         \n",
      "0          3  0\n",
      "1          5  2 \n",
      "\n",
      "PPV: 1.00 \n",
      "\n",
      "2 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "Predicted   0   1\n",
      "Actual           \n",
      "0          14  24\n",
      "1           2   2 \n",
      "\n",
      "PPV: 0.08 \n",
      "\n",
      "3 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "No cluster 3 data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classify_ext_data('..\\..\\data\\hm_score_based_efdata_binary.csv', 'hm_gh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors: ['s_score', 'Hits', 'max_feat', 'avg_feat', 'max_centr', 'min_centr', 'avg_centr', 'features', 'all_same', 'hyd_prop', 'don_prop', 'catdon_prop', 'hydaro_prop', 'aniacc_prop'] \n",
      "\n",
      "score based Q ph4s: 15 \n",
      "\n",
      "0 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "No cluster 0 data.\n",
      "\n",
      "1 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "Predicted  0  1\n",
      "Actual         \n",
      "0          2  0\n",
      "1          6  4 \n",
      "\n",
      "PPV: 1.00 \n",
      "\n",
      "2 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "Predicted   0   1\n",
      "Actual           \n",
      "0          13  22\n",
      "1           4   1 \n",
      "\n",
      "PPV: 0.04 \n",
      "\n",
      "3 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "No cluster 3 data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classify_ext_data('..\\..\\data\\hm_score_based_recefdata_binary.csv', 'hm_rec_ef')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors: ['s_score', 'Hits', 'max_feat', 'avg_feat', 'max_centr', 'min_centr', 'avg_centr', 'features', 'all_same', 'hyd_prop', 'don_prop', 'catdon_prop', 'hydaro_prop', 'aniacc_prop'] \n",
      "\n",
      "score based Q ph4s: 12 \n",
      "\n",
      "0 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "Predicted  0  1\n",
      "Actual         \n",
      "0          0  1\n",
      "1          2  5 \n",
      "\n",
      "PPV: 0.83 \n",
      "\n",
      "1 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "No cluster 1 data.\n",
      "\n",
      "2 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "Predicted   0   1\n",
      "Actual           \n",
      "0          15  24\n",
      "1           2   3 \n",
      "\n",
      "PPV: 0.11 \n",
      "\n",
      "3 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "No cluster 3 data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classify_ext_data('..\\..\\data\\hm_score_based_recghdata_binary.csv', 'hm_rec_gh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors: ['s_score', 'Hits', 'max_feat', 'avg_feat', 'max_centr', 'min_centr', 'avg_centr', 'features', 'all_same', 'hyd_prop', 'don_prop', 'catdon_prop', 'hydaro_prop'] \n",
      "\n",
      "0 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "No cluster 0 data.\n",
      "\n",
      "1 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "     s_score      Hits  max_feat  avg_feat  max_centr  min_centr  avg_centr  \\\n",
      "21 -0.111182 -0.696069  1.111583  0.981812   0.880114   0.461244   1.079794   \n",
      "29 -0.067695 -0.706324  1.321852  0.493215   1.120982   0.899270   1.359525   \n",
      "37  0.030912 -0.716580  1.321852  1.108692   1.120982   0.899270   1.204100   \n",
      "\n",
      "    features  all_same  hyd_prop  don_prop  catdon_prop  hydaro_prop  \\\n",
      "21       0.0 -0.538816 -0.226463 -0.816497     0.561548     1.538968   \n",
      "29       0.0 -0.538816 -0.703229 -0.816497     0.942259     1.538968   \n",
      "37       0.0 -0.538816 -0.703229 -0.816497     0.942259    -0.512989   \n",
      "\n",
      "    aniacc_prop  clusters              Receptor  hits_actual Score Type  \\\n",
      "21    -0.267261  -1.36277  GPR101_5ZKC_inactive            2         dE   \n",
      "29    -0.267261  -1.36277  GPR101_5ZKC_inactive            1         dE   \n",
      "37    -0.267261  -1.36277  GPR101_5ZKC_inactive            0         dE   \n",
      "\n",
      "      subset  quality_pred  \n",
      "21  moefrags             1  \n",
      "29        gh             1  \n",
      "37    rec_gh             1   \n",
      "\n",
      "2 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "     s_score      Hits  max_feat  avg_feat  max_centr  min_centr  avg_centr  \\\n",
      "0   0.496935 -0.470456  0.618669  0.561454   0.128391  -0.660837  -0.306940   \n",
      "2   0.737512  2.031805  0.396937  0.011223  -0.685094  -0.660837  -0.720478   \n",
      "4   0.506753  0.483275  0.618669  0.500210   0.128391  -0.660837   0.024740   \n",
      "6   0.408967  0.596081  0.396937  0.031883  -0.685094  -0.660837  -0.896230   \n",
      "8   0.399251 -0.470456  0.618669  0.561454   0.128391  -0.660837  -0.306940   \n",
      "9   0.529199  1.867722 -0.433811 -0.772172   0.614168  -0.484577   0.668287   \n",
      "10  0.646374  2.031805  0.396937  0.011224  -0.685094  -0.660837  -0.720477   \n",
      "12  0.194259  0.544806  0.469649  0.197502  -0.288910  -1.178886  -0.717330   \n",
      "14  0.093021 -0.234587  0.366329  0.024257  -0.288910  -1.061633  -0.783969   \n",
      "16  0.801647 -0.531987  0.246887  0.409493  -0.223056  -1.097427  -0.863452   \n",
      "17 -0.026903 -0.562752 -0.282375 -0.001355   0.073117  -0.838994  -0.292202   \n",
      "18  0.251442  2.503542 -0.583217 -0.754949  -0.747510  -0.977423  -1.483609   \n",
      "20  0.876390  1.221646 -0.318468 -0.017307   0.982683   0.366890   0.593275   \n",
      "22  0.716379  0.831950 -0.924910 -0.334072   0.758520   0.311513   0.470361   \n",
      "24  0.872532 -0.501221  1.387788  1.793672   0.982683   1.138647   0.830567   \n",
      "25  0.521481 -0.644793  1.452955  1.898732   0.684034   0.461244   0.476928   \n",
      "26  1.108816  1.119095  0.453813  0.111265   1.208540   1.138647   1.409090   \n",
      "28  0.958453  1.478026  0.207928  0.386664   0.982683   0.795748   0.637593   \n",
      "30  1.103565  2.195887 -0.924910 -0.929552   0.758520   1.138647   1.239829   \n",
      "32  0.479047 -0.603773  1.494865  1.301458   0.286866   0.461244   0.297999   \n",
      "33  0.215435 -0.552497  0.273087  0.871568  -0.235635   0.454968  -0.009587   \n",
      "34  1.102065 -0.326883 -0.829841 -1.293656   1.080552   1.060087   1.587528   \n",
      "36  1.079562 -0.521732  1.303617  1.503630   0.801243   1.141080   1.069268   \n",
      "38  1.108816 -0.490966  1.365084  1.092282   1.159411   1.998179   1.529503   \n",
      "\n",
      "    features  all_same  hyd_prop  don_prop  catdon_prop  hydaro_prop  \\\n",
      "0        0.0 -0.538816  0.250302  1.905159    -0.580584    -0.512989   \n",
      "2        0.0 -0.538816  0.727067  0.544331    -0.961295    -0.512989   \n",
      "4        0.0 -0.538816  0.250302  1.905159    -0.961295     1.538968   \n",
      "6        0.0 -0.538816  0.250302  0.544331    -0.961295    -0.512989   \n",
      "8        0.0 -0.538816  0.250302  1.905159    -0.580584    -0.512989   \n",
      "9        0.0 -0.538816 -0.226463  1.905159    -0.580584     3.590924   \n",
      "10       0.0 -0.538816  0.727067  0.544331    -0.961295    -0.512989   \n",
      "12       0.0 -0.538816  0.250302  0.544331    -0.961295    -0.512989   \n",
      "14       0.0 -0.538816 -0.226463  0.544331    -0.580584    -0.512989   \n",
      "16       0.0 -0.538816  0.727067 -0.816497    -0.199873    -0.512989   \n",
      "17       0.0 -0.538816  0.250302 -0.816497     0.180838    -0.512989   \n",
      "18       0.0 -0.538816  0.727067 -0.816497    -0.580584    -0.512989   \n",
      "20       0.0 -0.538816 -0.226463  0.544331    -0.961295     1.538968   \n",
      "22       0.0 -0.538816  1.203832 -0.816497    -0.961295    -0.512989   \n",
      "24       0.0 -0.538816 -0.226463  0.544331    -0.961295    -0.512989   \n",
      "25       0.0 -0.538816 -0.703229  0.544331    -0.580584     1.538968   \n",
      "26       0.0  1.855921  2.157362 -0.816497    -0.961295    -0.512989   \n",
      "28       0.0 -0.538816 -0.226463  0.544331    -0.961295     1.538968   \n",
      "30       0.0  1.855921  2.157362 -0.816497    -0.961295    -0.512989   \n",
      "32       0.0 -0.538816 -0.226463  0.544331    -0.580584    -0.512989   \n",
      "33       0.0 -0.538816 -1.179994  1.905159    -0.199873    -0.512989   \n",
      "34       0.0  1.855921  2.157362 -0.816497    -0.961295    -0.512989   \n",
      "36       0.0 -0.538816  1.680597 -0.816497    -0.961295    -0.512989   \n",
      "38       0.0  1.855921  2.157362 -0.816497    -0.961295    -0.512989   \n",
      "\n",
      "    aniacc_prop  clusters              Receptor  hits_actual Score Type  \\\n",
      "0     -0.267261  0.733799    GPR101_4MQS_active           24  dE(class)   \n",
      "2     -0.267261  0.733799    GPR101_4MQS_active          268  dU(class)   \n",
      "4     -0.267261  0.733799    GPR101_4MQS_active          117  dE(class)   \n",
      "6     -0.267261  0.733799    GPR101_4MQS_active          128  dU(class)   \n",
      "8     -0.267261  0.733799    GPR101_4MQS_active           24  dE(class)   \n",
      "9     -0.267261  0.733799    GPR101_4MQS_active          252         dE   \n",
      "10    -0.267261  0.733799    GPR101_4MQS_active          268  dU(class)   \n",
      "12    -0.267261  0.733799    GPR101_4MQS_active          123  dE(class)   \n",
      "14    -0.267261  0.733799    GPR101_4MQS_active           47  dU(class)   \n",
      "16    -0.267261  0.733799    GPR101_4MQS_active           18  dE(class)   \n",
      "17    -0.267261  0.733799    GPR101_4MQS_active           15         dE   \n",
      "18    -0.267261  0.733799    GPR101_4MQS_active          314  dU(class)   \n",
      "20     2.405351  0.733799  GPR101_5ZKC_inactive          189  dE(class)   \n",
      "22     5.077964  0.733799  GPR101_5ZKC_inactive          151  dU(class)   \n",
      "24    -0.267261  0.733799  GPR101_5ZKC_inactive           21  dE(class)   \n",
      "25    -0.267261  0.733799  GPR101_5ZKC_inactive            7         dE   \n",
      "26    -0.267261  0.733799  GPR101_5ZKC_inactive          179  dU(class)   \n",
      "28    -0.267261  0.733799  GPR101_5ZKC_inactive          214  dE(class)   \n",
      "30    -0.267261  0.733799  GPR101_5ZKC_inactive          284  dU(class)   \n",
      "32    -0.267261  0.733799  GPR101_5ZKC_inactive           11  dE(class)   \n",
      "33    -0.267261  0.733799  GPR101_5ZKC_inactive           16         dE   \n",
      "34    -0.267261  0.733799  GPR101_5ZKC_inactive           38  dU(class)   \n",
      "36    -0.267261  0.733799  GPR101_5ZKC_inactive           19  dE(class)   \n",
      "38    -0.267261  0.733799  GPR101_5ZKC_inactive           22  dU(class)   \n",
      "\n",
      "      subset  quality_pred  \n",
      "0   moefrags             1  \n",
      "2   moefrags             1  \n",
      "4         ef             1  \n",
      "6         ef             1  \n",
      "8         gh             1  \n",
      "9         gh             1  \n",
      "10        gh             1  \n",
      "12    rec_ef             1  \n",
      "14    rec_ef             1  \n",
      "16    rec_gh             1  \n",
      "17    rec_gh             1  \n",
      "18    rec_gh             1  \n",
      "20  moefrags             1  \n",
      "22  moefrags             1  \n",
      "24        ef             1  \n",
      "25        ef             1  \n",
      "26        ef             1  \n",
      "28        gh             1  \n",
      "30        gh             1  \n",
      "32    rec_ef             1  \n",
      "33    rec_ef             1  \n",
      "34    rec_ef             1  \n",
      "36    rec_gh             1  \n",
      "38    rec_gh             1   \n",
      "\n",
      "3 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "No cluster 3 data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classify_ext_data('..\\..\\data\\gpr101_data_binary_5feats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors: ['s_score', 'Hits', 'max_feat', 'avg_feat', 'max_centr', 'min_centr', 'avg_centr', 'features', 'all_same', 'hyd_prop', 'don_prop', 'catdon_prop', 'hydaro_prop'] \n",
      "\n",
      "0 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "No cluster 0 data.\n",
      "\n",
      "1 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "No cluster 1 data.\n",
      "\n",
      "2 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "     s_score      Hits  max_feat  avg_feat  max_centr  min_centr  avg_centr  \\\n",
      "0   0.496935 -0.380754  0.618669  0.561454   0.128391  -0.660837  -0.306940   \n",
      "4   0.506753  0.287235  0.618669  0.500210   0.128391  -0.660837   0.024740   \n",
      "6   0.408967  0.153637  0.396937  0.031883  -0.685094  -0.660837  -0.896230   \n",
      "8   0.399251 -0.380754  0.618669  0.561454   0.128391  -0.660837  -0.306940   \n",
      "12  0.194259 -0.113558  0.469649  0.197502  -0.288910  -1.178886  -0.717330   \n",
      "14  0.093021  0.020040  0.366329  0.024257  -0.288910  -1.061633  -0.783969   \n",
      "16  0.801647 -0.514352  0.246887  0.409493  -0.223056  -1.097427  -0.863452   \n",
      "17 -0.026903 -0.514352 -0.282375 -0.001355   0.073117  -0.838994  -0.292202   \n",
      "20  0.876390  0.153637 -0.318468 -0.017307   0.982683   0.366890   0.593275   \n",
      "21 -0.111182 -0.647949  1.111583  0.981812   0.880114   0.461244   1.079794   \n",
      "22  0.716379  1.088822 -0.924910 -0.334072   0.758520   0.311513   0.470361   \n",
      "24  0.872532 -0.247156  1.387788  1.793672   0.982683   1.138647   0.830567   \n",
      "25  0.521481 -0.514352  1.452955  1.898732   0.684034   0.461244   0.476928   \n",
      "29 -0.067695 -0.647949  1.321852  0.493215   1.120982   0.899270   1.359525   \n",
      "32  0.479047 -0.380754  1.494865  1.301458   0.286866   0.461244   0.297999   \n",
      "33  0.215435 -0.647949  0.273087  0.871568  -0.235635   0.454968  -0.009587   \n",
      "34  1.102065 -0.380754 -0.829841 -1.293656   1.080552   1.060087   1.587528   \n",
      "36  1.079562 -0.380754  1.303617  1.503630   0.801243   1.141080   1.069268   \n",
      "37  0.030912 -0.647949  1.321852  1.108692   1.120982   0.899270   1.204100   \n",
      "38  1.108816 -0.247156  1.365084  1.092282   1.159411   1.998179   1.529503   \n",
      "\n",
      "    features  all_same  hyd_prop  don_prop  catdon_prop  hydaro_prop  \\\n",
      "0        0.0 -0.538816  0.250302  1.905159    -0.580584    -0.512989   \n",
      "4        0.0 -0.538816  0.250302  1.905159    -0.961295     1.538968   \n",
      "6        0.0 -0.538816  0.250302  0.544331    -0.961295    -0.512989   \n",
      "8        0.0 -0.538816  0.250302  1.905159    -0.580584    -0.512989   \n",
      "12       0.0 -0.538816  0.250302  0.544331    -0.961295    -0.512989   \n",
      "14       0.0 -0.538816 -0.226463  0.544331    -0.580584    -0.512989   \n",
      "16       0.0 -0.538816  0.727067 -0.816497    -0.199873    -0.512989   \n",
      "17       0.0 -0.538816  0.250302 -0.816497     0.180838    -0.512989   \n",
      "20       0.0 -0.538816 -0.226463  0.544331    -0.961295     1.538968   \n",
      "21       0.0 -0.538816 -0.226463 -0.816497     0.561548     1.538968   \n",
      "22       0.0 -0.538816  1.203832 -0.816497    -0.961295    -0.512989   \n",
      "24       0.0 -0.538816 -0.226463  0.544331    -0.961295    -0.512989   \n",
      "25       0.0 -0.538816 -0.703229  0.544331    -0.580584     1.538968   \n",
      "29       0.0 -0.538816 -0.703229 -0.816497     0.942259     1.538968   \n",
      "32       0.0 -0.538816 -0.226463  0.544331    -0.580584    -0.512989   \n",
      "33       0.0 -0.538816 -1.179994  1.905159    -0.199873    -0.512989   \n",
      "34       0.0  1.855921  2.157362 -0.816497    -0.961295    -0.512989   \n",
      "36       0.0 -0.538816  1.680597 -0.816497    -0.961295    -0.512989   \n",
      "37       0.0 -0.538816 -0.703229 -0.816497     0.942259    -0.512989   \n",
      "38       0.0  1.855921  2.157362 -0.816497    -0.961295    -0.512989   \n",
      "\n",
      "    aniacc_prop  clusters              Receptor  hits_actual Score Type  \\\n",
      "0     -0.267261 -0.460566    GPR101_4MQS_active            2  dE(class)   \n",
      "4     -0.267261 -0.460566    GPR101_4MQS_active            7  dE(class)   \n",
      "6     -0.267261 -0.460566    GPR101_4MQS_active            6  dU(class)   \n",
      "8     -0.267261 -0.460566    GPR101_4MQS_active            2  dE(class)   \n",
      "12    -0.267261 -0.460566    GPR101_4MQS_active            4  dE(class)   \n",
      "14    -0.267261 -0.460566    GPR101_4MQS_active            5  dU(class)   \n",
      "16    -0.267261 -0.460566    GPR101_4MQS_active            1  dE(class)   \n",
      "17    -0.267261 -0.460566    GPR101_4MQS_active            1         dE   \n",
      "20     2.405351 -0.460566  GPR101_5ZKC_inactive            6  dE(class)   \n",
      "21    -0.267261 -0.460566  GPR101_5ZKC_inactive            0         dE   \n",
      "22     5.077964 -0.460566  GPR101_5ZKC_inactive           13  dU(class)   \n",
      "24    -0.267261 -0.460566  GPR101_5ZKC_inactive            3  dE(class)   \n",
      "25    -0.267261 -0.460566  GPR101_5ZKC_inactive            1         dE   \n",
      "29    -0.267261 -0.460566  GPR101_5ZKC_inactive            0         dE   \n",
      "32    -0.267261 -0.460566  GPR101_5ZKC_inactive            2  dE(class)   \n",
      "33    -0.267261 -0.460566  GPR101_5ZKC_inactive            0         dE   \n",
      "34    -0.267261 -0.460566  GPR101_5ZKC_inactive            2  dU(class)   \n",
      "36    -0.267261 -0.460566  GPR101_5ZKC_inactive            2  dE(class)   \n",
      "37    -0.267261 -0.460566  GPR101_5ZKC_inactive            0         dE   \n",
      "38    -0.267261 -0.460566  GPR101_5ZKC_inactive            3  dU(class)   \n",
      "\n",
      "      subset  quality_pred  \n",
      "0   moefrags             1  \n",
      "4         ef             1  \n",
      "6         ef             1  \n",
      "8         gh             1  \n",
      "12    rec_ef             1  \n",
      "14    rec_ef             1  \n",
      "16    rec_gh             1  \n",
      "17    rec_gh             1  \n",
      "20  moefrags             1  \n",
      "21  moefrags             1  \n",
      "22  moefrags             1  \n",
      "24        ef             1  \n",
      "25        ef             1  \n",
      "29        gh             1  \n",
      "32    rec_ef             1  \n",
      "33    rec_ef             1  \n",
      "34    rec_ef             1  \n",
      "36    rec_gh             1  \n",
      "37    rec_gh             1  \n",
      "38    rec_gh             1   \n",
      "\n",
      "3 cluster model\n",
      "\n",
      "---------------\n",
      "\n",
      "No cluster 3 data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classify_ext_data('..\\..\\data\\gpr101_data_binary_6feats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save models\n",
    "#import joblib\n",
    "#from joblib import dump, load\n",
    "\n",
    "#joblib.dump(sgdc0 , 'model_sgdc0')\n",
    "#joblib.dump(sgdc0 , 'model_sgdc1')\n",
    "#joblib.dump(sgdc0 , 'model_sgdc2')\n",
    "#joblib.dump(sgdc0 , 'model_sgdc3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
